from __future__ import print_function
from keras.applications.inception_v3 import InceptionV3
from keras.preprocessing import image
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
from keras import backend as K

# this is the model we will train
#model = Model(inputs=base_model.input, outputs=predictions)
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import np_utils
from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping
from keras.callbacks import ModelCheckpoint
import numpy as np
import resnet
import os
from keras.optimizers import SGD,Adam
import tensorflow as tf
os.environ["CUDA_VISIBLE_DEVICES"]="1"
# config = tf.ConfigProto()
# config.gpu_options.per_process_gpu_memory_fraction = 0.5
# session = tf.Session(config=config)
#lr_reducer = ReduceLROnPlateau(monitor='val_loss',factor=0.5, cooldown=0, patience=5, min_lr=0.5e-6)
csv_logger = CSVLogger('./inception_nucleus_centric_normalized.csv')
checkpointer = ModelCheckpoint(filepath='./weights/'+'weights_normalized_224_inception.{epoch:02d}-{val_loss:.2f}.h5', monitor='val_acc',verbose=1,save_best_only=True)
batchsize = 30
nb_classes = 2
epochs= 100
data_augmentation = True

# input image dimensions
img_rows, img_cols = 224, 224
# The patch images are RGB.
img_channels = 3
validation_size=99755
train_size=202732
train_data_dir='./normalized_dataset_224_black_thresholded/train'
val_data_dir='./normalized_dataset_224_black_thresholded/val'

sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)
#model = resnet.ResnetBuilder.build_resnet_50((img_channels, img_rows, img_cols), nb_classes)
# create the base pre-trained model
base_model = InceptionV3(weights='imagenet', include_top=False)

# add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)
# let's add a fully-connected layer
x = Dense(1024, activation='relu')(x)
# and a logistic layer -- let's say we have 200 classes
predictions = Dense(2, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)
for layer in model.layers[:249]:
   layer.trainable = False
for layer in model.layers[249:]:
   layer.trainable = True

model.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])

print('Using real-time data augmentation.')
# This will do preprocessing and realtime data augmentation:
datagen_train = ImageDataGenerator(
    rescale=1.0/255,
    #samplewise_center=True,  # set each sample mean to 0
    #samplewise_std_normalization=True,  # divide each input by its std
    horizontal_flip=True,  # randomly flip images
    vertical_flip=True)  # randomly flip images

datagen_val = ImageDataGenerator(
    rescale=1.0/255,
    #samplewise_center=True,  # set each sample mean to 0
    #samplewise_std_normalization=True
    )  # divide each input by its std

train_generator = datagen_train.flow_from_directory(
    train_data_dir,
    target_size=(224,224),
    batch_size=batchsize,
    class_mode='categorical')
val_generator = datagen_val.flow_from_directory(
    val_data_dir,
    target_size=(224,224),
    batch_size=batchsize,
    class_mode='categorical')

# Fit the model on the batches generated by datagen.flow_from_directory().
print(model.summary())
model.fit_generator(
    train_generator,
    steps_per_epoch=train_size // batchsize,
    epochs=epochs,
    verbose=1,
    validation_data=val_generator,
    validation_steps=validation_size// batchsize,callbacks=[csv_logger,checkpointer])

